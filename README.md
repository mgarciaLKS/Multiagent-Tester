# ü§ñ Multi-Agent Testing System# Multi-Agent Workflow System# Multi-Agent Workflow System



> Automated test generation using AI agents working in parallel



[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/downloads/)> A modular multi-agent system built with LangGraph, LangChain, and OpenAI GPT-4oA LangGraph-based multi-agent system with a supervisor pattern for handling various types of queries through specialized agents.

[![LangGraph](https://img.shields.io/badge/LangGraph-0.6.10-green.svg)](https://github.com/langchain-ai/langgraph)

[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-orange.svg)](https://openai.com/)

[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)]()

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)## Architecture

**Give it a Python project ‚Üí Get back a complete pytest test suite**

[![UV](https://img.shields.io/badge/uv-fast%20package%20manager-green.svg)](https://docs.astral.sh/uv/)

---

[![LangGraph](https://img.shields.io/badge/LangGraph-0.6.10-orange.svg)](https://langchain-ai.github.io/langgraph/)The system consists of the following components:

## ‚ö° What This Does



This system generates comprehensive test suites for Python projects using **5 specialized AI agents working in parallel**:

## ‚ú® Features### Agents (`agents.py`)

```

Your Project ‚Üí Parallel Testing Agents ‚Üí Complete Test Suite- **SupervisorAgent**: Orchestrates the workflow by routing to appropriate specialists

                     ‚Üì

         [Unit | Functional | Integration]- üéØ **Intelligent Routing** - Supervisor agent directs queries to specialists- **EnhancerAgent**: Improves and clarifies user queries

                All at once!

```- üîç **Query Enhancement** - Clarifies vague requests automatically- **ResearcherAgent**: Gathers information using web search (Tavily)



**Result**: Unit tests, integration tests, and functional tests - all generated simultaneously in ~2 minutes.- üåê **Web Research** - Real-time information via Tavily search- **CoderAgent**: Handles technical implementation and calculations



---- üíª **Code Execution** - Safe Python code execution with PythonREPL- **GenericAgent**: Processes general questions that don't require specialized handling



## üöÄ Quick Start- ‚úÖ **Quality Validation** - Ensures responses meet quality standards- **ValidatorAgent**: Validates response quality and decides whether to continue or finish



```bash- üì¶ **Modular Design** - Clean separation, easy to extend

# Clone

git clone https://github.com/mgarciaLKS/Multiagent-Tester.git### Workflow Orchestrator (`workflow.py`)

cd Multiagent-Tester

## üöÄ Quick Start (30 seconds)- **MultiAgentWorkflow**: Main class that initializes agents and manages the workflow graph

# Install

uv sync



# Configure```bash### Main Application (`main.py`)

echo "OPENAI_API_KEY=your_key_here" > .env

# Install UV package manager- Entry point with example usage scenarios

# Run

uv run python examples/demo.pycurl -LsSf https://astral.sh/uv/install.sh | sh

```

## Setup

**That's it!** See tests being generated in parallel.

# Set up environment

---

echo "OPENAI_API_KEY=your_key_here" > .env### Option 1: UV (Recommended - Fast & Modern)

## üí° Usage



```python

from multiagent_system import MultiAgentWorkflow# Install dependencies**Why UV?**



# Initializeuv sync- ‚ö° **10-100x faster** than pip for dependency resolution and installation

workflow = MultiAgentWorkflow()

- üîí **Reliable dependency locking** with uv.lock

# Generate tests

results = workflow.run_parallel_sync("""# Run demo- üêç **Python version management** built-in

    Generate comprehensive tests for /path/to/project

    uv run examples/demo.py- üì¶ **Modern pyproject.toml** standard support

    Include:

    - Unit tests for core functions```- üöÄ **Single binary** - no Python required for installation

    - Integration tests for APIs

    - Functional tests for workflows- üîÑ **Automatic virtual environment** management

    

    Requirements:## üì¶ Project Structure

    - pytest framework

    - 70%+ coverage#### 1. Install UV

    - Mock external dependencies

""")``````bash



# View resultstesting-multiagent/# Install UV (if not already installed)

workflow.print_results(results)

```‚îú‚îÄ‚îÄ multiagent_system/          # Main packagecurl -LsSf https://astral.sh/uv/install.sh | sh



---‚îÇ   ‚îú‚îÄ‚îÄ agents/                 # Agent implementationssource ~/.cargo/env



## ü§ñ The Team‚îÇ   ‚îú‚îÄ‚îÄ models/                 # Pydantic models```



Your AI testing team works in **parallel**:‚îÇ   ‚îî‚îÄ‚îÄ workflow.py             # Orchestrator



| Agent | Focuses On | Runtime |‚îú‚îÄ‚îÄ examples/                   # Usage examples#### 2. Quick Setup

|-------|-----------|---------|

| **Supervisor** | Project analysis & task routing | First |‚îÇ   ‚îî‚îÄ‚îÄ demo.py                 # Demo with 4 scenarios```bash

| **Unit Tester** | Individual functions with mocks | Parallel |

| **Functional Tester** | End-to-end user workflows | Parallel |‚îú‚îÄ‚îÄ docs/                       # üìö Complete documentation# Run the setup script

| **Integration Tester** | APIs, databases, external calls | Parallel |

| **Validator** | Quality & coverage validation | Last |‚îÇ   ‚îú‚îÄ‚îÄ INDEX.md                # Documentation navigation./setup.sh



**Key Feature**: The 3 testing agents run simultaneously, not sequentially!‚îÇ   ‚îú‚îÄ‚îÄ QUICK_REFERENCE.md      # Command cheat sheet```



---‚îÇ   ‚îú‚îÄ‚îÄ API_REFERENCE.md        # Complete API docs



## ‚ö° Why Parallel?‚îÇ   ‚îî‚îÄ‚îÄ ...                     # 7 more guides#### 3. Configure Environment Variables



**Before (Sequential)**:‚îú‚îÄ‚îÄ scripts/                    # Utility scriptsEdit the `.env` file created by setup:

```

Unit ‚Üí Wait ‚Üí Functional ‚Üí Wait ‚Üí Integration‚îú‚îÄ‚îÄ legacy/                     # Old files (reference)```bash

~6 minutes total

```‚îú‚îÄ‚îÄ .env                        # Environment variables# Required



**Now (Parallel)**:‚îî‚îÄ‚îÄ pyproject.toml              # UV configurationOPENAI_API_KEY=your_actual_openai_api_key

```

       ‚îå‚îÄ Unit Tester ‚îÄ‚îÄ‚îÄ‚îÄ‚îê```

Start ‚îÄ‚îú‚îÄ Functional Tester‚îú‚îÄ Done

       ‚îî‚îÄ Integration Tester‚îò# Optional (for enhanced functionality)  

~2 minutes total

```## üíª Basic UsageTAVILY_API_KEY=your_actual_tavily_api_key



**Result**: **3x faster** test generationLANGSMITH_API_KEY=your_actual_langsmith_api_key



---```pythonLANGFUSE_PUBLIC_KEY=your_actual_langfuse_public_key



## üìä Real Resultsfrom multiagent_system import MultiAgentWorkflowLANGFUSE_SECRET_KEY=your_actual_langfuse_secret_key



### Test Case: WhatsApp MCP Server```



**Input**: 3 Python files (~1,100 lines)  # Initialize workflow

**Time**: 2 minutes  

**Output**:workflow = MultiAgentWorkflow()#### 4. Run the Application



``````bash

‚úÖ 15+ unit tests with proper mocking

‚úÖ 8+ integration tests for API endpoints# Run a query# Test the setup

‚úÖ 5+ functional tests for user workflows

‚úÖ 70%+ code coverageworkflow.run_and_print("What is quantum computing?")uv run test_import.py

‚úÖ 100% pytest best practices

``````



**Generated Test Example**:# Run the main application

```python

import pytest## ü§ñ Available Agentsuv run run.py

from unittest.mock import Mock, patch



def test_convert_to_ogg_success():

    """Test successful audio conversion"""| Agent | Purpose | Tools |# Or use the script entry point

    with patch('subprocess.run') as mock_run:

        mock_run.return_value = Mock(returncode=0)|-------|---------|-------|uv run workflow-demo

        result = convert_to_ogg('input.mp3', 'output.ogg')

        assert result == 'output.ogg'| **Supervisor** | Routes to specialists | None |```

```

| **Enhancer** | Clarifies queries | None |

---

| **Researcher** | Web search | Tavily |### Option 2: Traditional pip

## üèóÔ∏è Architecture

| **Coder** | Code execution | PythonREPL |

```

User Request| **Generic** | General Q&A | None |#### 1. Install Dependencies

     ‚Üì

Supervisor (analyzes project)| **Validator** | Quality check | None |```bash

     ‚Üì

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îêpip install -r requirements.txt

‚îÇ Unit Tester  ‚îÇ Functional Test ‚îÇ Integration Test  ‚îÇ

‚îÇ (parallel)   ‚îÇ (parallel)      ‚îÇ (parallel)        ‚îÇ## üìö Documentation```

‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

     ‚Üì

Validator (checks quality)

     ‚ÜìAll documentation is in the [`docs/`](docs/) folder:#### 2. Configure Environment Variables  

Complete Test Suite ‚úÖ

```Copy the `.env` file and fill in your API keys



---- **[INDEX.md](docs/INDEX.md)** - Start here! Master navigation guide



## üìÅ Project Structure- **[QUICK_REFERENCE.md](docs/QUICK_REFERENCE.md)** - Command cheat sheet#### 3. Run the Application



```- **[API_REFERENCE.md](docs/API_REFERENCE.md)** - Complete API documentation```bash

Multiagent-Tester/

‚îú‚îÄ‚îÄ multiagent_system/- **[MODULAR_STRUCTURE.md](docs/MODULAR_STRUCTURE.md)** - Architecture detailspython main.py

‚îÇ   ‚îú‚îÄ‚îÄ agents/              # 5 specialized agents

‚îÇ   ‚îú‚îÄ‚îÄ models/              # Pydantic models- **[TESTING_GUIDE.md](docs/TESTING_GUIDE.md)** - Testing strategies```

‚îÇ   ‚îî‚îÄ‚îÄ parallel_workflow.py # Parallel execution engine

‚îú‚îÄ‚îÄ examples/- **[COMPLETE_DOCUMENTATION.md](docs/COMPLETE_DOCUMENTATION.md)** - All-in-one reference

‚îÇ   ‚îî‚îÄ‚îÄ demo.py             # Main demonstration

‚îú‚îÄ‚îÄ docs/                    # Complete documentation## Usage

‚îî‚îÄ‚îÄ pyproject.toml          # UV configuration

```**Total**: 11 comprehensive documents (~134 KB, ~70 pages)



---### UV Commands



## üéØ Features## üîß Environment Variables



### ‚úÖ What It Does#### Quick Task Runner



- **Parallel Execution**: 3x faster than sequential approaches### Required```bash

- **Automatic Test Generation**: Complete pytest test suites

- **Smart Mocking**: Automatically mocks external dependencies```bash# Show all available tasks

- **Quality Validation**: Ensures 70%+ coverage

- **Edge Case Testing**: Includes error scenariosOPENAI_API_KEY=sk-...              # OpenAI API keyuv run tasks.py help

- **Best Practices**: Follows pytest conventions

```

### üîÆ Coming Soon

# Initial setup (sync + test)

- Test execution and reporting

- Code coverage visualization### Optionaluv run tasks.py setup

- Multi-language support (JavaScript, Java, Go)

- CI/CD pipeline integration```bash

- Web UI

TAVILY_API_KEY=tvly-...            # For web search (researcher agent)# Test the installation

---

LANGSMITH_API_KEY=...              # For LangSmith tracinguv run tasks.py test

## üìö Documentation

LANGSMITH_TRACING=true

| Document | Description |

|----------|-------------|LANGFUSE_PUBLIC_KEY=...            # For Langfuse monitoring# Run the full demo

| [docs/README.md](docs/README.md) | Complete guide with examples |

| [docs/API_REFERENCE.md](docs/API_REFERENCE.md) | API documentation |LANGFUSE_SECRET_KEY=...uv run tasks.py demo

| [docs/QUICK_REFERENCE.md](docs/QUICK_REFERENCE.md) | Quick start commands |

| [docs/MODULAR_STRUCTURE.md](docs/MODULAR_STRUCTURE.md) | Architecture details |```



---# Add new dependencies



## üõ†Ô∏è Configuration## üß™ Testinguv run tasks.py add requests



### Environment Variables



```bash```bash# Format code

# Required

OPENAI_API_KEY=your_openai_key# Run demouv run tasks.py format



# Optionaluv run examples/demo.py

TAVILY_API_KEY=your_tavily_key      # For web search

LANGSMITH_API_KEY=your_langsmith_key # For tracing# Lint code  

```

# Test importsuv run tasks.py lint

### Custom Model

uv run python -c "from multiagent_system import *; print('‚úÖ OK')"```

```python

workflow = MultiAgentWorkflow(model_name="gpt-4o-mini")

```

# Interactive mode#### Direct UV Commands

---

uv run python```bash

## üéì Learn More

>>> from multiagent_system import MultiAgentWorkflow# Test the installation

### Quick Path (10 min)

1. Run `uv run python examples/demo.py`>>> workflow = MultiAgentWorkflow()uv run test_import.py

2. Review [docs/QUICK_REFERENCE.md](docs/QUICK_REFERENCE.md)

3. Try with your own project>>> workflow.run_and_print("Your question")



### Deep Dive (1 hour)```# Run the full demo

1. Read [docs/README.md](docs/README.md)

2. Study [docs/MODULAR_STRUCTURE.md](docs/MODULAR_STRUCTURE.md)uv run run.py

3. Review [docs/API_REFERENCE.md](docs/API_REFERENCE.md)

## üéØ Example Queries

---

# Run with script entry point

## üìà Performance

```bashuv run workflow-demo

| Metric | Value |

|--------|-------|# Research query (uses researcher agent)

| **Speed** | 3x faster than sequential |

| **Efficiency** | All agents run concurrently |uv run python -c "# Add new dependencies

| **Coverage** | 70%+ achieved automatically |

| **Quality** | 100% pytest best practices |from multiagent_system import MultiAgentWorkflowuv add requests beautifulsoup4

| **Success Rate** | 100% in production tests |

MultiAgentWorkflow().run_and_print('Latest AI trends 2024')

---

"# Install development dependencies

## ü§ù Contributing

uv sync --group dev

Contributions welcome!

# Coding query (uses coder agent)

1. Fork the repo

2. Create feature branch (`git checkout -b feature/amazing`)uv run python -c "# Run with specific Python version

3. Commit changes (`git commit -m 'Add feature'`)

4. Push (`git push origin feature/amazing`)from multiagent_system import MultiAgentWorkflowuv run --python 3.11 run.py

5. Open Pull Request

MultiAgentWorkflow().run_and_print('Calculate Fibonacci 20')

---

"# Sync dependencies

## üìù License

uv sync

MIT License - see LICENSE file

# General query (uses generic agent)```

---

uv run python -c "

## üôè Built With

from multiagent_system import MultiAgentWorkflow### Basic Usage (Code)

- [LangGraph](https://github.com/langchain-ai/langgraph) - Multi-agent orchestration

- [LangChain](https://github.com/langchain-ai/langchain) - LLM frameworkMultiAgentWorkflow().run_and_print('What is the capital of France?')```python

- [OpenAI](https://openai.com/) - GPT-4o model

- [UV](https://github.com/astral-sh/uv) - Fast Python package manager"from workflow import MultiAgentWorkflow



---```



## üìû Support# Initialize the workflow



- **Issues**: [GitHub Issues](https://github.com/mgarciaLKS/Multiagent-Tester/issues)## üõ†Ô∏è Developmentworkflow = MultiAgentWorkflow()

- **Docs**: [docs/](docs/)

- **Examples**: [examples/](examples/)



---### Add Custom Agent# Process a query



## üéâ Success Storyworkflow.run_and_print("Tell me a short story")



**WhatsApp MCP Server Project**```python```



- ‚è±Ô∏è **Time**: 2 minutes (vs 6 sequential)# 1. Create agent file

- ‚úÖ **Tests**: 28+ comprehensive tests

- üìä **Coverage**: 70%+ achievedfrom multiagent_system.agents import BaseAgent### Advanced Usage with Custom Configuration

- üéØ **Quality**: 100% passing, proper mocking

```python

All three agent types completed successfully with proper subprocess mocking, database testing, and API endpoint testing.

class CustomAgent(BaseAgent):from workflow import MultiAgentWorkflow

---

    def process(self, state):

**Version**: 2.0.0 (Parallel Execution)  

**Status**: üü¢ Production Ready          # Your logic here# Initialize with custom model

**Last Updated**: November 10, 2025

        passworkflow = MultiAgentWorkflow(model_name="gpt-4")

‚≠ê **Star this repo** if you find it useful!



# 2. Add to workflow# Run with custom configuration

# See docs/MODULAR_STRUCTURE.md for detailsconfig = {"callbacks": [your_callback_handler]}

```for event in workflow.run("Calculate the 20th Fibonacci number", config):

    # Process events as needed

### Run Tests    pass

```

```bash

# Install test dependencies## Features

uv sync --extra test

- **Supervisor Pattern**: Intelligent routing to appropriate specialist agents

# Run tests- **Flexible Architecture**: Easy to extend with new agents

uv run pytest- **Environment Validation**: Automatic checking of required configurations

```- **Multiple Examples**: Pre-built examples for different query types

- **Optional Integrations**: Support for LangSmith and LangFuse tracing

## üìñ Learn More

## Agent Workflow

### For Beginners

1. Read [docs/INDEX.md](docs/INDEX.md) - Documentation navigation1. **Supervisor** receives the user query

2. Read [docs/QUICK_REFERENCE.md](docs/QUICK_REFERENCE.md) - Commands2. **Supervisor** routes to appropriate specialist:

3. Run `uv run examples/demo.py` - Try it out   - **Enhancer** for query clarification

   - **Researcher** for information gathering

### For Developers   - **Coder** for technical/mathematical tasks

1. Read [docs/MODULAR_STRUCTURE.md](docs/MODULAR_STRUCTURE.md) - Architecture   - **Generic** for simple general questions

2. Read [docs/API_REFERENCE.md](docs/API_REFERENCE.md) - API details3. Specialist processes the query

3. Read [docs/TESTING_GUIDE.md](docs/TESTING_GUIDE.md) - Write tests4. **Validator** checks the response quality

5. Either finish (if satisfactory) or route back to **Supervisor** for further processing

### For Complete Understanding

- Read [docs/COMPLETE_DOCUMENTATION.md](docs/COMPLETE_DOCUMENTATION.md) - Everything!## Requirements



## üîó Resources- Python 3.8+

- OpenAI API key (required)

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)- Tavily API key (optional, for web search)

- [LangChain Documentation](https://python.langchain.com/)- LangSmith credentials (optional, for tracing)

- [UV Package Manager](https://docs.astral.sh/uv/)- LangFuse credentials (optional, for monitoring)

- [OpenAI API](https://platform.openai.com/docs)

## Original vs Refactored

## üìù License

This is a refactored version of the original Google Colab notebook with the following improvements:

[Your License Here]

- ‚úÖ Removed Google Colab dependencies

## üôè Acknowledgments- ‚úÖ Added proper class-based architecture

- ‚úÖ Separated concerns into different modules

Built with LangChain, LangGraph, OpenAI, Tavily, and UV.- ‚úÖ Added environment variable management

- ‚úÖ Added proper error handling

---- ‚úÖ Added comprehensive documentation

- ‚úÖ Made the system easily extensible

**Version**: 1.0.0 | **Status**: Production Ready ‚úÖ | **Documentation**: [`docs/`](docs/)
